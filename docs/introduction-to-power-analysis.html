<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Introduction to Power Analysis | Power Analysis with Superpower</title>
  <meta name="description" content="This is a book describing the capabilities of the Superpower R package." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Introduction to Power Analysis | Power Analysis with Superpower" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a book describing the capabilities of the Superpower R package." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introduction to Power Analysis | Power Analysis with Superpower" />
  
  <meta name="twitter:description" content="This is a book describing the capabilities of the Superpower R package." />
  

<meta name="author" content="Aaron R. Caldwell, Daniël Lakens, Chelsea M. Parlett-Pelleriti, and Guy Prochilo" />


<meta name="date" content="2021-03-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="the-experimental-design.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i>Contributors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#funding"><i class="fa fa-check"></i>Funding</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html"><i class="fa fa-check"></i><b>1</b> Introduction to Power Analysis</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html#overview-of-power-analysis"><i class="fa fa-check"></i><b>1.1</b> Overview of Power Analysis</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html#error-and-power"><i class="fa fa-check"></i><b>1.2</b> Error and Power</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html#effect-size"><i class="fa fa-check"></i><b>1.3</b> Effect size</a></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html#samp_vs_pop"><i class="fa fa-check"></i><b>1.4</b> Sample effect size vs. population effect size</a></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html#safeguard-effect-size"><i class="fa fa-check"></i><b>1.5</b> Safeguard Effect Size</a></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html#post-hoc-power-analysis"><i class="fa fa-check"></i><b>1.6</b> <em>Post hoc</em> power analysis</a><ul>
<li class="chapter" data-level="1.6.1" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html#the-sample-effect-size-is-not-the-population-effect-size"><i class="fa fa-check"></i><b>1.6.1</b> The sample effect size is <em>not</em> the population effect size</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html#post-hoc-power-is-merely-a-transformation-of-your-obtained-p-value"><i class="fa fa-check"></i><b>1.6.2</b> <em>Post hoc</em> power is merely a transformation of your obtained <em>p</em> value</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction-to-power-analysis.html"><a href="introduction-to-power-analysis.html#the-minimal-detectable-effect-size"><i class="fa fa-check"></i><b>1.7</b> The Minimal Detectable Effect Size</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-experimental-design.html"><a href="the-experimental-design.html"><i class="fa fa-check"></i><b>2</b> The Experimental Design</a><ul>
<li class="chapter" data-level="2.1" data-path="the-experimental-design.html"><a href="the-experimental-design.html#anova_design-function"><i class="fa fa-check"></i><b>2.1</b> ANOVA_design function</a><ul>
<li class="chapter" data-level="2.1.1" data-path="the-experimental-design.html"><a href="the-experimental-design.html#specifying-the-design-using-design"><i class="fa fa-check"></i><b>2.1.1</b> Specifying the design using <code>design</code></a></li>
<li class="chapter" data-level="2.1.2" data-path="the-experimental-design.html"><a href="the-experimental-design.html#specifying-the-means-using-mu"><i class="fa fa-check"></i><b>2.1.2</b> Specifying the means using <code>mu</code></a></li>
<li class="chapter" data-level="2.1.3" data-path="the-experimental-design.html"><a href="the-experimental-design.html#specifying-label-names"><i class="fa fa-check"></i><b>2.1.3</b> Specifying label names</a></li>
<li class="chapter" data-level="2.1.4" data-path="the-experimental-design.html"><a href="the-experimental-design.html#specifying-the-correlation"><i class="fa fa-check"></i><b>2.1.4</b> Specifying the correlation</a></li>
<li class="chapter" data-level="2.1.5" data-path="the-experimental-design.html"><a href="the-experimental-design.html#specifying-the-sample-size"><i class="fa fa-check"></i><b>2.1.5</b> Specifying the sample size</a></li>
<li class="chapter" data-level="2.1.6" data-path="the-experimental-design.html"><a href="the-experimental-design.html#specifying-the-standard-deviation"><i class="fa fa-check"></i><b>2.1.6</b> Specifying the standard deviation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="one-way-anova.html"><a href="one-way-anova.html"><i class="fa fa-check"></i><b>3</b> One-Way ANOVA</a><ul>
<li class="chapter" data-level="3.1" data-path="one-way-anova.html"><a href="one-way-anova.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="one-way-anova.html"><a href="one-way-anova.html#two-conditions"><i class="fa fa-check"></i><b>3.1.1</b> Two conditions</a></li>
<li class="chapter" data-level="3.1.2" data-path="one-way-anova.html"><a href="one-way-anova.html#three-conditions"><i class="fa fa-check"></i><b>3.1.2</b> Three conditions</a></li>
<li class="chapter" data-level="3.1.3" data-path="one-way-anova.html"><a href="one-way-anova.html#power-for-simple-effects"><i class="fa fa-check"></i><b>3.1.3</b> Power for simple effects</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="one-way-anova.html"><a href="one-way-anova.html#effect-size-estimates-for-one-way-anova"><i class="fa fa-check"></i><b>3.2</b> Effect Size Estimates for One-Way ANOVA</a><ul>
<li class="chapter" data-level="3.2.1" data-path="one-way-anova.html"><a href="one-way-anova.html#three-conditions-small-effect-size"><i class="fa fa-check"></i><b>3.2.1</b> Three conditions, small effect size</a></li>
<li class="chapter" data-level="3.2.2" data-path="one-way-anova.html"><a href="one-way-anova.html#four-conditions-medium-effect-size"><i class="fa fa-check"></i><b>3.2.2</b> Four conditions, medium effect size</a></li>
<li class="chapter" data-level="3.2.3" data-path="one-way-anova.html"><a href="one-way-anova.html#two-conditions-large-effect-size"><i class="fa fa-check"></i><b>3.2.3</b> Two conditions, large effect size</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html"><i class="fa fa-check"></i><b>4</b> Repeated Measures ANOVA</a><ul>
<li class="chapter" data-level="4.1" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#part-1"><i class="fa fa-check"></i><b>4.1</b> Part 1</a><ul>
<li class="chapter" data-level="4.1.1" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#two-conditions-medium-effect-size"><i class="fa fa-check"></i><b>4.1.1</b> Two conditions, medium effect size</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#part-2"><i class="fa fa-check"></i><b>4.2</b> Part 2</a><ul>
<li class="chapter" data-level="4.2.1" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#the-relation-between-cohens-f-and-cohens-d"><i class="fa fa-check"></i><b>4.2.1</b> The relation between Cohen’s f and Cohen’s d</a></li>
<li class="chapter" data-level="4.2.2" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#three-within-conditions-medium-effect-size"><i class="fa fa-check"></i><b>4.2.2</b> Three within conditions, medium effect size</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#part-3"><i class="fa fa-check"></i><b>4.3</b> Part 3</a></li>
<li class="chapter" data-level="4.4" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#part-4"><i class="fa fa-check"></i><b>4.4</b> Part 4</a><ul>
<li class="chapter" data-level="4.4.1" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#x2-anova-within-within-design"><i class="fa fa-check"></i><b>4.4.1</b> 2x2 ANOVA, within-within design</a></li>
<li class="chapter" data-level="4.4.2" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#examine-variation-of-means-and-correlation"><i class="fa fa-check"></i><b>4.4.2</b> Examine variation of means and correlation</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#part-5"><i class="fa fa-check"></i><b>4.5</b> Part 5</a><ul>
<li class="chapter" data-level="4.5.1" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#x2-anova-within-design"><i class="fa fa-check"></i><b>4.5.1</b> 2x2 ANOVA, within design</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#multivariate-anova-manova"><i class="fa fa-check"></i><b>4.6</b> Multivariate ANOVA (MANOVA)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mixed-anova.html"><a href="mixed-anova.html"><i class="fa fa-check"></i><b>5</b> Mixed ANOVA</a><ul>
<li class="chapter" data-level="5.1" data-path="mixed-anova.html"><a href="mixed-anova.html#simple-mixed-designs"><i class="fa fa-check"></i><b>5.1</b> Simple Mixed Designs</a></li>
<li class="chapter" data-level="5.2" data-path="mixed-anova.html"><a href="mixed-anova.html#complex-mixed-designs"><i class="fa fa-check"></i><b>5.2</b> Complex Mixed Designs</a><ul>
<li class="chapter" data-level="5.2.1" data-path="mixed-anova.html"><a href="mixed-anova.html#b3w-design"><i class="fa fa-check"></i><b>5.2.1</b> 2b*3w Design</a></li>
<li class="chapter" data-level="5.2.2" data-path="mixed-anova.html"><a href="mixed-anova.html#b4w-design"><i class="fa fa-check"></i><b>5.2.2</b> 2b*4w Design</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="power-for-three-way-interactions.html"><a href="power-for-three-way-interactions.html"><i class="fa fa-check"></i><b>6</b> Power for Three-way Interactions</a></li>
<li class="chapter" data-level="7" data-path="the-no-way-interactions.html"><a href="the-no-way-interactions.html"><i class="fa fa-check"></i><b>7</b> The ‘No-Way’ Interactions</a></li>
<li class="chapter" data-level="8" data-path="effect-of-varying-designs-on-power.html"><a href="effect-of-varying-designs-on-power.html"><i class="fa fa-check"></i><b>8</b> Effect of Varying Designs on Power</a><ul>
<li class="chapter" data-level="8.1" data-path="effect-of-varying-designs-on-power.html"><a href="effect-of-varying-designs-on-power.html#within-designs"><i class="fa fa-check"></i><b>8.1</b> Within Designs</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="error-control-in-exploratory-anova.html"><a href="error-control-in-exploratory-anova.html"><i class="fa fa-check"></i><b>9</b> Error Control in Exploratory ANOVA</a></li>
<li class="chapter" data-level="10" data-path="analytic-power-functions.html"><a href="analytic-power-functions.html"><i class="fa fa-check"></i><b>10</b> Analytic Power Functions</a><ul>
<li class="chapter" data-level="10.1" data-path="analytic-power-functions.html"><a href="analytic-power-functions.html#one-way-between-subjects-anova"><i class="fa fa-check"></i><b>10.1</b> One-Way Between Subjects ANOVA</a></li>
<li class="chapter" data-level="10.2" data-path="analytic-power-functions.html"><a href="analytic-power-functions.html#two-way-between-subject-interaction"><i class="fa fa-check"></i><b>10.2</b> Two-way Between Subject Interaction</a></li>
<li class="chapter" data-level="10.3" data-path="analytic-power-functions.html"><a href="analytic-power-functions.html#x3-between-subject-anova"><i class="fa fa-check"></i><b>10.3</b> 3x3 Between Subject ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="power-curve.html"><a href="power-curve.html"><i class="fa fa-check"></i><b>11</b> Power Curve</a><ul>
<li class="chapter" data-level="11.1" data-path="power-curve.html"><a href="power-curve.html#explore-increase-in-effect-size-for-moderated-interactions."><i class="fa fa-check"></i><b>11.1</b> Explore increase in effect size for moderated interactions.</a></li>
<li class="chapter" data-level="11.2" data-path="power-curve.html"><a href="power-curve.html#explore-increase-in-effect-size-for-cross-over-interactions."><i class="fa fa-check"></i><b>11.2</b> Explore increase in effect size for cross-over interactions.</a></li>
<li class="chapter" data-level="11.3" data-path="power-curve.html"><a href="power-curve.html#explore-increase-in-correlation-in-moderated-interactions."><i class="fa fa-check"></i><b>11.3</b> Explore increase in correlation in moderated interactions.</a></li>
<li class="chapter" data-level="11.4" data-path="power-curve.html"><a href="power-curve.html#increasing-correlation-in-on-factor-decreases-power-in-second-factor"><i class="fa fa-check"></i><b>11.4</b> Increasing correlation in on factor decreases power in second factor</a></li>
<li class="chapter" data-level="11.5" data-path="power-curve.html"><a href="power-curve.html#code-to-reproduce-power-curve-figures"><i class="fa fa-check"></i><b>11.5</b> Code to Reproduce Power Curve Figures</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="violations-of-assumptions.html"><a href="violations-of-assumptions.html"><i class="fa fa-check"></i><b>12</b> Violations of Assumptions</a><ul>
<li class="chapter" data-level="12.1" data-path="violations-of-assumptions.html"><a href="violations-of-assumptions.html#violation-of-heterogeneity-assumption"><i class="fa fa-check"></i><b>12.1</b> Violation of Heterogeneity Assumption</a></li>
<li class="chapter" data-level="12.2" data-path="violations-of-assumptions.html"><a href="violations-of-assumptions.html#violation-of-the-sphericity-assumption"><i class="fa fa-check"></i><b>12.2</b> Violation of the sphericity assumption</a><ul>
<li class="chapter" data-level="12.2.1" data-path="violations-of-assumptions.html"><a href="violations-of-assumptions.html#manova-or-sphericity-adjustment"><i class="fa fa-check"></i><b>12.2.1</b> MANOVA or Sphericity Adjustment?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="estimated-marginal-means.html"><a href="estimated-marginal-means.html"><i class="fa fa-check"></i><b>13</b> Estimated Marginal Means</a><ul>
<li class="chapter" data-level="13.1" data-path="estimated-marginal-means.html"><a href="estimated-marginal-means.html#a-note-of-caution"><i class="fa fa-check"></i><b>13.1</b> A note of caution</a></li>
<li class="chapter" data-level="13.2" data-path="estimated-marginal-means.html"><a href="estimated-marginal-means.html#pairwise-comparisons"><i class="fa fa-check"></i><b>13.2</b> Pairwise Comparisons</a></li>
<li class="chapter" data-level="13.3" data-path="estimated-marginal-means.html"><a href="estimated-marginal-means.html#customized-emmeans-contrasts"><i class="fa fa-check"></i><b>13.3</b> Customized <code>emmeans</code> contrasts</a></li>
<li class="chapter" data-level="13.4" data-path="estimated-marginal-means.html"><a href="estimated-marginal-means.html#equivalence-and-non-superiority-inferiority-tests"><i class="fa fa-check"></i><b>13.4</b> Equivalence and non-superiority/-inferiority tests</a></li>
<li class="chapter" data-level="13.5" data-path="estimated-marginal-means.html"><a href="estimated-marginal-means.html#joint-tests"><i class="fa fa-check"></i><b>13.5</b> Joint tests</a></li>
<li class="chapter" data-level="13.6" data-path="estimated-marginal-means.html"><a href="estimated-marginal-means.html#monte-carlo-simulations"><i class="fa fa-check"></i><b>13.6</b> Monte Carlo Simulations</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="beyond-superpower-i-mixed-models-with-simr.html"><a href="beyond-superpower-i-mixed-models-with-simr.html"><i class="fa fa-check"></i><b>14</b> Beyond Superpower I: Mixed Models with <code>simr</code></a><ul>
<li class="chapter" data-level="14.1" data-path="beyond-superpower-i-mixed-models-with-simr.html"><a href="beyond-superpower-i-mixed-models-with-simr.html#how-does-simr-work"><i class="fa fa-check"></i><b>14.1</b> How does <code>simr</code> work?</a></li>
<li class="chapter" data-level="14.2" data-path="beyond-superpower-i-mixed-models-with-simr.html"><a href="beyond-superpower-i-mixed-models-with-simr.html#to-be-continued"><i class="fa fa-check"></i><b>14.2</b> To Be Continued…</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html"><i class="fa fa-check"></i><b>15</b> Beyond Superpower II: Custom Simulations</a><ul>
<li class="chapter" data-level="15.1" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html#a-clincal-trial-with-a-binary-outcome"><i class="fa fa-check"></i><b>15.1</b> A Clincal Trial with a Binary Outcome</a><ul>
<li class="chapter" data-level="15.1.1" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html#proposed-study-and-approach"><i class="fa fa-check"></i><b>15.1.1</b> Proposed Study and Approach</a></li>
<li class="chapter" data-level="15.1.2" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html#step-1-create-a-data-generating-function"><i class="fa fa-check"></i><b>15.1.2</b> Step 1: Create a Data Generating Function</a></li>
<li class="chapter" data-level="15.1.3" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html#step-2-simulation"><i class="fa fa-check"></i><b>15.1.3</b> Step 2: Simulation</a></li>
<li class="chapter" data-level="15.1.4" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html#why-more-complicated-code"><i class="fa fa-check"></i><b>15.1.4</b> Why more complicated code?</a></li>
<li class="chapter" data-level="15.1.5" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html#conclusions-on-the-binary-rct-analysis"><i class="fa fa-check"></i><b>15.1.5</b> Conclusions on the Binary RCT Analysis</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html#binary-rct-with-a-interim-analysis"><i class="fa fa-check"></i><b>15.2</b> Binary RCT with a Interim Analysis</a><ul>
<li class="chapter" data-level="15.2.1" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html#proposed-study-and-approach-1"><i class="fa fa-check"></i><b>15.2.1</b> Proposed Study and Approach</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="beyond-superpower-ii-custom-simulations.html"><a href="beyond-superpower-ii-custom-simulations.html#conclusion-on-a-binary-rct-with-interim-analyses"><i class="fa fa-check"></i><b>15.3</b> Conclusion on a Binary RCT with Interim Analyses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html"><i class="fa fa-check"></i>Appendix 1: Direct Comparison to pwr2ppl</a><ul>
<li class="chapter" data-level="15.4" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html#examples-from-chapter-5"><i class="fa fa-check"></i><b>15.4</b> Examples from Chapter 5</a><ul>
<li class="chapter" data-level="15.4.1" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html#example-5.15.2"><i class="fa fa-check"></i><b>15.4.1</b> Example 5.1/5.2</a></li>
<li class="chapter" data-level="15.4.2" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html#example-5.3"><i class="fa fa-check"></i><b>15.4.2</b> Example 5.3</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html#examples-from-chapter-6"><i class="fa fa-check"></i><b>15.5</b> Examples from Chapter 6</a><ul>
<li class="chapter" data-level="15.5.1" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html#example-from-table-6.2"><i class="fa fa-check"></i><b>15.5.1</b> Example from Table 6.2</a></li>
<li class="chapter" data-level="15.5.2" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html#example-from-table-6.6"><i class="fa fa-check"></i><b>15.5.2</b> Example from Table 6.6</a></li>
<li class="chapter" data-level="15.5.3" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html#example-from-table-6.8"><i class="fa fa-check"></i><b>15.5.3</b> Example from Table 6.8</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html#example-from-chapter-7"><i class="fa fa-check"></i><b>15.6</b> Example from Chapter 7</a><ul>
<li class="chapter" data-level="15.6.1" data-path="appendix-1-direct-comparison-to-pwr2ppl.html"><a href="appendix-1-direct-comparison-to-pwr2ppl.html#from-table-7.2"><i class="fa fa-check"></i><b>15.6.1</b> From Table 7.2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-direct-comparison-to-morepower.html"><a href="appendix-2-direct-comparison-to-morepower.html"><i class="fa fa-check"></i>Appendix 2: Direct Comparison to MOREpower</a></li>
<li class="chapter" data-level="" data-path="appendix-3-comparison-to-brysbaert.html"><a href="appendix-3-comparison-to-brysbaert.html"><i class="fa fa-check"></i>Appendix 3: Comparison to Brysbaert</a><ul>
<li class="chapter" data-level="15.7" data-path="appendix-3-comparison-to-brysbaert.html"><a href="appendix-3-comparison-to-brysbaert.html#one-way-anova-1"><i class="fa fa-check"></i><b>15.7</b> One-Way ANOVA</a><ul>
<li class="chapter" data-level="15.7.1" data-path="appendix-3-comparison-to-brysbaert.html"><a href="appendix-3-comparison-to-brysbaert.html#three-conditions-replication"><i class="fa fa-check"></i><b>15.7.1</b> Three conditions replication</a></li>
<li class="chapter" data-level="15.7.2" data-path="appendix-3-comparison-to-brysbaert.html"><a href="appendix-3-comparison-to-brysbaert.html#variation-1"><i class="fa fa-check"></i><b>15.7.2</b> Variation 1</a></li>
<li class="chapter" data-level="15.7.3" data-path="appendix-3-comparison-to-brysbaert.html"><a href="appendix-3-comparison-to-brysbaert.html#three-conditions-replication-1"><i class="fa fa-check"></i><b>15.7.3</b> Three conditions replication</a></li>
<li class="chapter" data-level="15.7.4" data-path="appendix-3-comparison-to-brysbaert.html"><a href="appendix-3-comparison-to-brysbaert.html#variation-2"><i class="fa fa-check"></i><b>15.7.4</b> Variation 2</a></li>
<li class="chapter" data-level="15.7.5" data-path="appendix-3-comparison-to-brysbaert.html"><a href="appendix-3-comparison-to-brysbaert.html#three-conditions-replication-2"><i class="fa fa-check"></i><b>15.7.5</b> Three conditions replication</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="appendix-3-comparison-to-brysbaert.html"><a href="appendix-3-comparison-to-brysbaert.html#repeated-measures"><i class="fa fa-check"></i><b>15.8</b> Repeated Measures</a><ul>
<li class="chapter" data-level="15.8.1" data-path="appendix-3-comparison-to-brysbaert.html"><a href="appendix-3-comparison-to-brysbaert.html#reproducing-brysbaert-variation-1-changing-correlation"><i class="fa fa-check"></i><b>15.8.1</b> Reproducing Brysbaert Variation 1: Changing Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Power Analysis with Superpower</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-power-analysis" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction to Power Analysis</h1>
<p>In this first chapter we will introduce some basic concepts of power analysis. If you are already familiar with these concepts please feel free to move onto the next chapter where we discuss the specifics of how <code>Superpower</code> can used.</p>
<div id="overview-of-power-analysis" class="section level2">
<h2><span class="header-section-number">1.1</span> Overview of Power Analysis</h2>
<p>The goal of Neyman-Pearson hypothesis testing, often divisively labeled null hypothesis significance testing (NHST), is to determine whether the null hypothesis (<span class="math inline">\(H_0\)</span>) can be rejected. <em>Statistical power</em> is the probability of rejecting the null hypothesis when it is false. And a <em>power analysis</em> is a sample size planning procedure performed for a future <em>yet-to-be-conducted</em> study that will tell us how many observations are required to reject the null hypothesis with sufficiently high probability.</p>
<p>For example, if you want to plan a study with 80% power, a power analysis will answer the question:</p>
<blockquote>
<p>“<em>If I were to repeat my experiment many thousands of times, what sample size will allow me to reject the null hypothesis on 80% of these occasions?</em>”</p>
</blockquote>
<p>Let’s illustrate this with an example. Imagine we have conducted a literature review and have estimated that the true standardized mean difference betwen two groups is <span class="math inline">\(\delta\)</span> = 0.50. That is, the mean of each group differs by 0.50 standard deviations. Assuming that our estimate of this population effect size is accurate, how many observations per group should we collect to reject a null hypothesis of no difference with 80% probability?</p>
<p><em>Probability</em> is the long-run frequency at which an event occurs (i.e., after many repeated samples). Therefore, we if we want to determine the sample size that allows us to reject the null hypothesis with 80% probability, we can run a simulation of our study at different sample sizes where each study is repeated many thousands of times. Power will be the proportion of these studies, at each sample size, that reject the null hypothesis.</p>
<!-- To demonstrate this we will set up a function called `power_sim()`. This function requires the following parameters: -->
<!-- * `n`: The sample size (per group) at which we want to determine power. -->
<!-- * `d`: The estimated standardized mean difference between two groups. -->
<!-- * `nsims`: The number of simulations of your study to replicate at a given sample size. -->
<!-- * `seed`: A logical indicating whether to use a random number generation seed for replicable results. -->
<!-- * `print_plot`: A logical indicating whether to print the plot generated by this function. -->
<!-- These parameters are fed to a `replicate()` function - the work horse of our simulation. This function performs `nsims` number of simulations, where in each simulation it draws `n` samples from two normal distributions where the true standardized mean difference is `d`. After doing this, it performs an independent groups *t* test on the two samples, and the *p* values for every *t* test is stored in a variable called `ps`. The `power` variable is computed by taking the sum of all simulations that yield *p* < .05 (i.e., which reject the null hypothesis), and this sum is divided by the total number of `nsims` performed. This final proportion is our estimated power for our given sample size per group, `n`. Finally, the function returns a matrix that pairs your inputted sample size `n` with the power of this sample size. We also include a nice plot to visualize how these computations are performed. Here is our function: -->
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="introduction-to-power-analysis.html#cb1-1"></a><span class="co"># Define our power analysis simulation function</span></span>
<span id="cb1-2"><a href="introduction-to-power-analysis.html#cb1-2"></a>power_sim &lt;-<span class="st"> </span><span class="cf">function</span>(n, d, nsims, <span class="dt">seed =</span> <span class="ot">TRUE</span>, <span class="dt">print_plot =</span> <span class="ot">TRUE</span>){</span>
<span id="cb1-3"><a href="introduction-to-power-analysis.html#cb1-3"></a>  </span>
<span id="cb1-4"><a href="introduction-to-power-analysis.html#cb1-4"></a><span class="cf">if</span>(seed <span class="op">==</span><span class="st"> </span><span class="ot">TRUE</span>){<span class="kw">set.seed</span>(<span class="dv">2</span>)}</span>
<span id="cb1-5"><a href="introduction-to-power-analysis.html#cb1-5"></a>  </span>
<span id="cb1-6"><a href="introduction-to-power-analysis.html#cb1-6"></a><span class="co"># For sample size `n`, we want to perform `nsims` number of simulations of our experiment using effect size `d`</span></span>
<span id="cb1-7"><a href="introduction-to-power-analysis.html#cb1-7"></a>  <span class="kw">replicate</span>(<span class="dt">n =</span> nsims, <span class="dt">exp =</span> {</span>
<span id="cb1-8"><a href="introduction-to-power-analysis.html#cb1-8"></a>    x1 =<span class="st"> </span><span class="kw">rnorm</span>(n, d, <span class="dv">1</span>)</span>
<span id="cb1-9"><a href="introduction-to-power-analysis.html#cb1-9"></a>    x2 =<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb1-10"><a href="introduction-to-power-analysis.html#cb1-10"></a>    <span class="kw">t.test</span>(<span class="dt">x =</span> x1, <span class="dt">y =</span> x2, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)<span class="op">$</span>p.value}) -&gt;<span class="st"> </span>ps</span>
<span id="cb1-11"><a href="introduction-to-power-analysis.html#cb1-11"></a></span>
<span id="cb1-12"><a href="introduction-to-power-analysis.html#cb1-12"></a><span class="co"># Power for a given `n` is the long-run probability of rejecting the null hypothesis when it is true. In our simulation, it is the sum of all  `nsims` simulations of our study that yield p &lt; .05 divided by the number of `nsims` performed. </span></span>
<span id="cb1-13"><a href="introduction-to-power-analysis.html#cb1-13"></a>  power =<span class="st"> </span><span class="kw">sum</span>(ps <span class="op">&lt;</span><span class="st"> </span><span class="fl">.05</span>) <span class="op">/</span><span class="st"> </span>nsims</span>
<span id="cb1-14"><a href="introduction-to-power-analysis.html#cb1-14"></a>  result =<span class="st"> </span><span class="kw">cbind</span>(n, power)</span>
<span id="cb1-15"><a href="introduction-to-power-analysis.html#cb1-15"></a>  </span>
<span id="cb1-16"><a href="introduction-to-power-analysis.html#cb1-16"></a><span class="co"># Visualize the results as a plot</span></span>
<span id="cb1-17"><a href="introduction-to-power-analysis.html#cb1-17"></a>  ps <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb1-18"><a href="introduction-to-power-analysis.html#cb1-18"></a><span class="st">    </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span></span>
<span id="cb1-19"><a href="introduction-to-power-analysis.html#cb1-19"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .)) <span class="op">+</span></span>
<span id="cb1-20"><a href="introduction-to-power-analysis.html#cb1-20"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.01</span>) <span class="op">+</span></span>
<span id="cb1-21"><a href="introduction-to-power-analysis.html#cb1-21"></a><span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> scales<span class="op">::</span><span class="kw">pretty_breaks</span>(<span class="dt">n =</span> <span class="dv">15</span>)) <span class="op">+</span></span>
<span id="cb1-22"><a href="introduction-to-power-analysis.html#cb1-22"></a><span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">0.05</span>,</span>
<span id="cb1-23"><a href="introduction-to-power-analysis.html#cb1-23"></a>               <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>,</span>
<span id="cb1-24"><a href="introduction-to-power-analysis.html#cb1-24"></a>               <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span></span>
<span id="cb1-25"><a href="introduction-to-power-analysis.html#cb1-25"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="dt">label =</span> <span class="kw">expression</span>(<span class="kw">italic</span>(p) <span class="op">~</span><span class="st"> &quot;value&quot;</span>)) <span class="op">+</span></span>
<span id="cb1-26"><a href="introduction-to-power-analysis.html#cb1-26"></a><span class="st">    </span><span class="kw">ylab</span>(<span class="dt">label =</span> <span class="st">&quot;Frequency&quot;</span>) <span class="op">+</span></span>
<span id="cb1-27"><a href="introduction-to-power-analysis.html#cb1-27"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">caption =</span> <span class="kw">paste</span>(</span>
<span id="cb1-28"><a href="introduction-to-power-analysis.html#cb1-28"></a>      <span class="st">&quot;Power =&quot;</span>,</span>
<span id="cb1-29"><a href="introduction-to-power-analysis.html#cb1-29"></a>      power <span class="op">*</span><span class="st"> </span><span class="dv">100</span>,</span>
<span id="cb1-30"><a href="introduction-to-power-analysis.html#cb1-30"></a>      <span class="st">&quot;% </span><span class="ch">\n</span><span class="st">&quot;</span>,</span>
<span id="cb1-31"><a href="introduction-to-power-analysis.html#cb1-31"></a>      <span class="kw">sum</span>(ps <span class="op">&lt;</span><span class="st"> </span><span class="fl">.05</span>),</span>
<span id="cb1-32"><a href="introduction-to-power-analysis.html#cb1-32"></a>      <span class="st">&quot;of&quot;</span>,</span>
<span id="cb1-33"><a href="introduction-to-power-analysis.html#cb1-33"></a>      nsims,</span>
<span id="cb1-34"><a href="introduction-to-power-analysis.html#cb1-34"></a>      <span class="st">&quot;simulations yield p &lt; .05&quot;</span></span>
<span id="cb1-35"><a href="introduction-to-power-analysis.html#cb1-35"></a>    )) <span class="op">+</span></span>
<span id="cb1-36"><a href="introduction-to-power-analysis.html#cb1-36"></a><span class="st">    </span><span class="kw">ggtitle</span>(<span class="dt">label =</span> <span class="kw">expr</span>(<span class="kw">paste</span>(</span>
<span id="cb1-37"><a href="introduction-to-power-analysis.html#cb1-37"></a>      <span class="st">&quot;N = &quot;</span>,<span class="op">!!</span>(n <span class="op">*</span><span class="st"> </span><span class="dv">2</span>),</span>
<span id="cb1-38"><a href="introduction-to-power-analysis.html#cb1-38"></a>      <span class="st">&quot; (&quot;</span>, n[<span class="dv">1</span>], <span class="st">&quot; = &quot;</span>,<span class="op">!!</span>n, <span class="st">&quot;; &quot;</span>, n[<span class="dv">2</span>], <span class="st">&quot; = &quot;</span>,<span class="op">!!</span>n, <span class="st">&quot;)&quot;</span></span>
<span id="cb1-39"><a href="introduction-to-power-analysis.html#cb1-39"></a>    ))) -&gt;<span class="st"> </span>pl</span>
<span id="cb1-40"><a href="introduction-to-power-analysis.html#cb1-40"></a>  </span>
<span id="cb1-41"><a href="introduction-to-power-analysis.html#cb1-41"></a>  <span class="co"># Print our plot</span></span>
<span id="cb1-42"><a href="introduction-to-power-analysis.html#cb1-42"></a>  <span class="cf">if</span>(print_plot <span class="op">==</span><span class="st"> </span><span class="ot">TRUE</span>){<span class="kw">print</span>(pl)}</span>
<span id="cb1-43"><a href="introduction-to-power-analysis.html#cb1-43"></a></span>
<span id="cb1-44"><a href="introduction-to-power-analysis.html#cb1-44"></a>  <span class="co"># Return the result variable</span></span>
<span id="cb1-45"><a href="introduction-to-power-analysis.html#cb1-45"></a>  <span class="kw">return</span>(result)</span>
<span id="cb1-46"><a href="introduction-to-power-analysis.html#cb1-46"></a>  </span>
<span id="cb1-47"><a href="introduction-to-power-analysis.html#cb1-47"></a>}</span></code></pre></div>
<p>We can use this function to compute power for any given sample size we like. For example, let’s determine the power of detecting <span class="math inline">\(\delta\)</span> = 0.50 if we were to collect <em>n</em> = 20 observations per group with 5000 simulations.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="introduction-to-power-analysis.html#cb2-1"></a><span class="kw">power_sim</span>(<span class="dt">n =</span> <span class="dv">20</span>, <span class="dt">d =</span> <span class="fl">0.50</span>, <span class="dt">nsims =</span> <span class="dv">5000</span>, <span class="dt">seed =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="SuperpowerValidation_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre><code>##       n  power
## [1,] 20 0.3456</code></pre>
<p>In the above plot, the red dashed line marks <em>p</em> = .05. As we can see, the majority of our simulated studies report <em>p</em> values greater than .05. In fact, only 1728 of our 5000 simulated studies rejected the null hypothesis with this sample size. Recall that probability is the long-run frequency at which an event occurs (i.e., after many repeated samples), and power is the probability of rejecting the null hypothesis when it is false. If we divide the 1728 correct rejections by the 5000 total simulations we get a final power estimate for this sample size: 34.56%. That is, after many, many repetitions of our study with a sample size of <em>n</em> = 20 per group, we only reject the null hypothesis 34.56% of the time. If we were planning a study to detect <span class="math inline">\(\delta\)</span> = 0.50, there is not a high probability that we will reject the null hypothesis with only <em>n</em> = 20 per group. We probably wouldn’t want to use this sample size.</p>
<p>Let’s try <em>n</em> = 50 per group.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="introduction-to-power-analysis.html#cb4-1"></a><span class="kw">power_sim</span>(<span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">d =</span> <span class="fl">0.50</span>, <span class="dt">nsims =</span> <span class="dv">5000</span>, <span class="dt">seed =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="SuperpowerValidation_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre><code>##       n  power
## [1,] 50 0.6954</code></pre>
<p>As we can see in the plot of our results, 3477 studies of our 5000 simulated studies rejected the null hypothesis. This corresponds to a power of 69.54%. Is rejecting the null hypothesis around 70% of the time satisfactory for you? It isn’t for most scientists.</p>
<p>Let’s try again with <em>n</em> = 80 per group.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="introduction-to-power-analysis.html#cb6-1"></a><span class="kw">power_sim</span>(<span class="dt">n =</span> <span class="dv">80</span>, <span class="dt">d =</span> <span class="fl">0.50</span>, <span class="dt">nsims =</span> <span class="dv">5000</span>, <span class="dt">seed =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="SuperpowerValidation_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre><code>##       n power
## [1,] 80 0.887</code></pre>
<p>This time 4435 of our simulated 5000 studies rejected the null hypothesis, corresponding to a power of 88.7%. This is usually more than enough power for most scientists to consider satisfactory. We might even consider examining power for lower sample sizes.</p>
<p>And that’s it. That’s all there is to power analysis. Power is simply the probability of rejecting the null hypothesis when it is false. And a power analysis will tell us how many observations are needed to reject this null hypothesis with a sufficiently high probability. Analytic solutions have been determined for many of the common tests you will encounter in psychological science, so simulations like those above are not always necessary. The analytic solution for the <em>t</em> test is implemented by the <code>pwr::pwr.t.test()</code> function as part of the <code>pwr</code> package. In fact, if we input the parameters for our last power analysis into <code>pwr::pwr.t.test()</code>, we will obtain almost identical power estimates for <em>n</em> = 80 per group:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="introduction-to-power-analysis.html#cb8-1"></a>pwr<span class="op">::</span><span class="kw">pwr.t.test</span>(<span class="dt">n =</span> <span class="dv">80</span>, <span class="dt">d =</span> <span class="fl">0.50</span>, <span class="dt">sig.level =</span> <span class="fl">0.05</span>)</span></code></pre></div>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 80
##               d = 0.5
##       sig.level = 0.05
##           power = 0.8816025
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>For <em>n</em> = 80 per group our simulation reported power = 88.7%, and the analytic solution reported power = 88.2%. If we were to increase the number of simulations we performed (perhaps to many hundreds of thousands), these two results would converge even closer.</p>
<p>Power analysis is essential before embarking on any research study. As we will discuss in subsequent section, with high power you are more likely to obtain findings that are trustworthy and you are more likely to draw correct inferences from your results. This is important, not only for getting your findings published, but also for building a reliable literature that is built on cumulative knowledge.</p>
</div>
<div id="error-and-power" class="section level2">
<h2><span class="header-section-number">1.2</span> Error and Power</h2>
<p>In this Neyman-Pearson framework there are two kinds of errors that we must account for when desiging an experimental study. These are:</p>
<ol style="list-style-type: decimal">
<li><p>Type I Error: rejecting the null hypothesis when it is true (also known as false positives or <span class="math inline">\(\alpha\)</span>).</p></li>
<li><p>Type II Error: failing to reject the null hypothesis when it is true (also known as false negatives or <span class="math inline">\(\beta\)</span>).</p></li>
</ol>
<p>Recall that power is the probability of rejecting the null hypothesis when it is false. This corresponds to <span class="math inline">\(1-\beta\)</span>. Power will depend crucially on sample size, effect size, and the Type I error rates that you are willing to accept.</p>
<p>The typical power analysis parameters in psychology are as follows:</p>
<ul>
<li><p><span class="math inline">\(\beta = .20\)</span></p>
<ul>
<li>This means we are willing to make a Type II error 20% of the time (i.e., 80% power).</li>
</ul></li>
<li><p><span class="math inline">\(\alpha = .05\)</span></p>
<ul>
<li>This means we are willing to make a Type I error only 5% of the time (i.e., significance &lt; .05.</li>
</ul></li>
<li><p><span class="math inline">\(1-\beta = .80\)</span>:</p>
<ul>
<li>This means we want to be able to correctly reject the null hypothesis, with a effect size <em>at least as large</em> as hypothesized, when it is false at least 80% of the time.</li>
</ul></li>
</ul>
<p>The values of each of these parameters reflect our relative concerns regarding the cost of Type I and Type II errors. That is, we regard Type I errors as <em>four times</em> more serious than making a Type II error:</p>
<p><span class="math display">\[\frac{\beta}{\alpha} = \frac{.20}{.05} = 4\]</span>
This may not always be the case and we may want to design a study where the errors are balanced:</p>
<p><span class="math display">\[\frac{\beta}{\alpha} = \frac{.05}{.05} = 1\]</span></p>
<p>And other times we may be willing to increase our Type I error rate slightly in order to reduce the Type II error rate. For example, we may raise our Type I error rate slightly in order to reduce the ratio of errors.</p>
<p><span class="math display">\[\frac{\beta}{\alpha} = \frac{.15}{.075} = 2\]</span></p>
</div>
<div id="effect-size" class="section level2">
<h2><span class="header-section-number">1.3</span> Effect size</h2>
<p>For any given <span class="math inline">\(\alpha\)</span> level, the power of a test will increase as the effect size increases. An effect size is a measure of the magnitude of some phenomenon. This might include a measure of the difference between two groups (e.g., the mean), the strength of association between variables (e.g., <em>r</em>: the Pearson’s correlation coefficient), or the linear relationship between a dependent variable and one or more predictors (e.g., <em>b</em>: the unstandardized regression coefficient).</p>
<p>A very common way to quantify effect size in psychological science is Cohen’s <em>d</em>. This quantity represents the standardized difference between two means. It is computed as:</p>
<p><span class="math display">\[d = \frac{M_1-M_2}{SD_{pool}}\]</span></p>
<p>Where <span class="math inline">\(M_1\)</span> is the mean of group one, <span class="math inline">\(M_2\)</span> is the mean of group two, and <span class="math inline">\(SD_{pool}\)</span> is the pooled standard deviation of group one and two. Cohen’s <em>d</em> is sometimes given descriptive labels of small, moderate, and large that correspond to 0.2, 0.5, and 0.8, respectively. However, these descriptives can differ across different measurements. We would strongly advocate against using these “default” interpretation scales and instead understand your phenomena/measurements well enough to understand when an effect is meaningful <span class="citation">(Caldwell and Vigotsky <a href="#ref-Caldwell2020" role="doc-biblioref">2020</a>)</span>. Some additional common effect sizes alongside their descriptive magnitudes are given in the following table:</p>
<table class="table table-striped" style="">
<thead>
<tr>
<th style="text-align:left;">
Effect
</th>
<th style="text-align:right;">
Small
</th>
<th style="text-align:right;">
Moderate
</th>
<th style="text-align:right;">
Large
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<em>d</em>
</td>
<td style="text-align:right;">
0.20
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.80
</td>
</tr>
<tr>
<td style="text-align:left;">
<em>r</em>
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.24
</td>
<td style="text-align:right;">
0.37
</td>
</tr>
<tr>
<td style="text-align:left;">
<em>f</em>
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.25
</td>
<td style="text-align:right;">
0.40
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\eta^2\)</span>
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.06
</td>
<td style="text-align:right;">
0.14
</td>
</tr>
</tbody>
</table>
</div>
<div id="samp_vs_pop" class="section level2">
<h2><span class="header-section-number">1.4</span> Sample effect size vs. population effect size</h2>
<p>When we run a study what we are doing is collecting a sample of the total population. It follows that any effect sizes computed on the sample data are an <strong><em>estimate of the true population effect size</em></strong>. This is an important consideration to keep in mind when performing power analyses. As <span class="citation">Albers and Lakens (<a href="#ref-albers2018power" role="doc-biblioref">2018</a>)</span> demonstrate, researchers are very likely to miss out on interesting effects when studies are powered to detect previously observed effect sizes.</p>
<p>To make this clear, imagine two groups with a known population standardized mean difference of <span class="math inline">\(Cohen&#39;s \ \delta = 0.5\)</span>. (We use the Greek symbol <span class="math inline">\(\delta\)</span> to refer to the population effect size, and the lower case <span class="math inline">\(d\)</span> to refer to the sample effect size). Now imagine that we have take a random sample of 20 measurements from each of these groups. We can simulate this in R using <code>rnorm()</code>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="introduction-to-power-analysis.html#cb10-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb10-2"><a href="introduction-to-power-analysis.html#cb10-2"></a><span class="kw">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb10-3"><a href="introduction-to-power-analysis.html#cb10-3"></a></span>
<span id="cb10-4"><a href="introduction-to-power-analysis.html#cb10-4"></a><span class="co"># Simulate datasets with mean difference of 0.5</span></span>
<span id="cb10-5"><a href="introduction-to-power-analysis.html#cb10-5"></a>group_<span class="dv">1</span> =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">20</span>, <span class="dt">mean =</span> <span class="fl">0.5</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</span>
<span id="cb10-6"><a href="introduction-to-power-analysis.html#cb10-6"></a>group_<span class="dv">2</span> =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">20</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</span>
<span id="cb10-7"><a href="introduction-to-power-analysis.html#cb10-7"></a></span>
<span id="cb10-8"><a href="introduction-to-power-analysis.html#cb10-8"></a><span class="co"># Visualize the data</span></span>
<span id="cb10-9"><a href="introduction-to-power-analysis.html#cb10-9"></a><span class="kw">data.frame</span>(group_<span class="dv">1</span>, group_<span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb10-10"><a href="introduction-to-power-analysis.html#cb10-10"></a><span class="st">  </span>tidyr<span class="op">::</span><span class="kw">pivot_longer</span>(</span>
<span id="cb10-11"><a href="introduction-to-power-analysis.html#cb10-11"></a>    <span class="dt">names_to =</span> <span class="st">&quot;group&quot;</span>, </span>
<span id="cb10-12"><a href="introduction-to-power-analysis.html#cb10-12"></a>    <span class="dt">values_to =</span> <span class="st">&quot;dv&quot;</span>, </span>
<span id="cb10-13"><a href="introduction-to-power-analysis.html#cb10-13"></a>    <span class="dt">cols =</span> <span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb10-14"><a href="introduction-to-power-analysis.html#cb10-14"></a><span class="st">  </span>GGally<span class="op">::</span><span class="kw">ggpairs</span>(ggplot2<span class="op">::</span><span class="kw">aes</span>(<span class="dt">colour =</span> group), </span>
<span id="cb10-15"><a href="introduction-to-power-analysis.html#cb10-15"></a>                  <span class="dt">lower =</span> <span class="kw">list</span>(<span class="dt">combo =</span> <span class="kw">wrap</span>(ggally_facethist, </span>
<span id="cb10-16"><a href="introduction-to-power-analysis.html#cb10-16"></a>                                            <span class="dt">binwidth =</span> <span class="fl">0.5</span>)))</span></code></pre></div>
<p><img src="SuperpowerValidation_files/figure-html/unnamed-chunk-8-1.png" width="100%" /></p>
<p>The above plot visualizes Group 1 (red) and Group 2 (teal) from left to right as: (1) counts, (2) box plots, (3) rotated histograms, and (4) density distributions. We can see clearly that the mean of Group 1 is greater than Group 2.</p>
<p>Now let’s compute the sample Cohen’s <em>d</em> using the formula we described earlier. We will also compute a 95% CI on Cohen’s <em>d</em> using the exact method implemented by <code>MBESS::ci.smd()</code>. The 95% CI will give us all plausible values of Cohen’s <span class="math inline">\(\delta\)</span>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="introduction-to-power-analysis.html#cb11-1"></a><span class="co"># Determine N for each group</span></span>
<span id="cb11-2"><a href="introduction-to-power-analysis.html#cb11-2"></a>n1 =<span class="st"> </span><span class="kw">length</span>(group_<span class="dv">1</span>)</span>
<span id="cb11-3"><a href="introduction-to-power-analysis.html#cb11-3"></a>n2 =<span class="st"> </span><span class="kw">length</span>(group_<span class="dv">2</span>)</span>
<span id="cb11-4"><a href="introduction-to-power-analysis.html#cb11-4"></a></span>
<span id="cb11-5"><a href="introduction-to-power-analysis.html#cb11-5"></a><span class="co"># Determine standard deviation for each group</span></span>
<span id="cb11-6"><a href="introduction-to-power-analysis.html#cb11-6"></a>sd1 =<span class="st"> </span><span class="kw">sd</span>(group_<span class="dv">1</span>)</span>
<span id="cb11-7"><a href="introduction-to-power-analysis.html#cb11-7"></a>sd2 =<span class="st"> </span><span class="kw">sd</span>(group_<span class="dv">2</span>)</span>
<span id="cb11-8"><a href="introduction-to-power-analysis.html#cb11-8"></a></span>
<span id="cb11-9"><a href="introduction-to-power-analysis.html#cb11-9"></a><span class="co"># Compute pooled standard deviation</span></span>
<span id="cb11-10"><a href="introduction-to-power-analysis.html#cb11-10"></a>sd_pool =<span class="st"> </span><span class="kw">sqrt</span>((sd1 <span class="op">*</span><span class="st"> </span>sd1 <span class="op">*</span><span class="st"> </span>(n1 <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>sd2 <span class="op">*</span><span class="st"> </span>sd2 <span class="op">*</span><span class="st"> </span>(n2 <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">/</span><span class="st"> </span>(n1 <span class="op">+</span><span class="st"> </span>n2 <span class="op">-</span><span class="st"> </span><span class="dv">2</span>))</span>
<span id="cb11-11"><a href="introduction-to-power-analysis.html#cb11-11"></a></span>
<span id="cb11-12"><a href="introduction-to-power-analysis.html#cb11-12"></a><span class="co"># Determine the difference between the means</span></span>
<span id="cb11-13"><a href="introduction-to-power-analysis.html#cb11-13"></a>m_diff =<span class="st"> </span><span class="kw">mean</span>(group_<span class="dv">1</span>) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(group_<span class="dv">2</span>)</span>
<span id="cb11-14"><a href="introduction-to-power-analysis.html#cb11-14"></a></span>
<span id="cb11-15"><a href="introduction-to-power-analysis.html#cb11-15"></a><span class="co"># Compute Cohen&#39;s d</span></span>
<span id="cb11-16"><a href="introduction-to-power-analysis.html#cb11-16"></a>d =<span class="st"> </span>m_diff <span class="op">/</span><span class="st"> </span>sd_pool</span>
<span id="cb11-17"><a href="introduction-to-power-analysis.html#cb11-17"></a></span>
<span id="cb11-18"><a href="introduction-to-power-analysis.html#cb11-18"></a><span class="co"># Compute 95% CI on Cohen&#39;s d</span></span>
<span id="cb11-19"><a href="introduction-to-power-analysis.html#cb11-19"></a>(<span class="dt">d_ci =</span> MBESS<span class="op">::</span><span class="kw">ci.smd</span>(<span class="dt">smd =</span> d, <span class="dt">n.1 =</span> n1, <span class="dt">n.2 =</span> n2, <span class="dt">conf.level =</span> <span class="fl">0.95</span>))</span></code></pre></div>
<pre><code>## $Lower.Conf.Limit.smd
## [1] -0.01853137
## 
## $smd
## [1] 0.6205506
## 
## $Upper.Conf.Limit.smd
## [1] 1.251871</code></pre>
<p>Recall that another name for Cohen’s <em>d</em> is the standardized mean difference (here, <code>smd</code>). Cohen’s <em>d</em> on our data is 0.62, and the 95% CI ranges from -0.02 to 1.25. Let’s visualize this as a plot (because we love plots):</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="introduction-to-power-analysis.html#cb13-1"></a><span class="co"># Plot the result</span></span>
<span id="cb13-2"><a href="introduction-to-power-analysis.html#cb13-2"></a>d_ci <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb13-3"><a href="introduction-to-power-analysis.html#cb13-3"></a><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb13-4"><a href="introduction-to-power-analysis.html#cb13-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="st">&quot;Cohen&#39;s d&quot;</span>)) <span class="op">+</span></span>
<span id="cb13-5"><a href="introduction-to-power-analysis.html#cb13-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> smd)) <span class="op">+</span></span>
<span id="cb13-6"><a href="introduction-to-power-analysis.html#cb13-6"></a><span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Lower.Conf.Limit.smd,</span>
<span id="cb13-7"><a href="introduction-to-power-analysis.html#cb13-7"></a>                    <span class="dt">ymax =</span> Upper.Conf.Limit.smd), <span class="dt">width =</span> <span class="fl">0.1</span>) <span class="op">+</span></span>
<span id="cb13-8"><a href="introduction-to-power-analysis.html#cb13-8"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span></span>
<span id="cb13-9"><a href="introduction-to-power-analysis.html#cb13-9"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb13-10"><a href="introduction-to-power-analysis.html#cb13-10"></a>        <span class="dt">axis.text.x =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb13-11"><a href="introduction-to-power-analysis.html#cb13-11"></a>        <span class="dt">axis.ticks.x =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></span>
<span id="cb13-12"><a href="introduction-to-power-analysis.html#cb13-12"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="dt">label =</span> <span class="st">&quot;Cohen&#39;s d&quot;</span>) <span class="op">+</span></span>
<span id="cb13-13"><a href="introduction-to-power-analysis.html#cb13-13"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">caption =</span> <span class="st">&quot;Note: Error bar = 95% CI&quot;</span>)</span></code></pre></div>
<p><img src="SuperpowerValidation_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>So what do these results tell us? Although we know with certainty that the population effect size is a Cohen’s <span class="math inline">\(\delta\)</span> of 0.5, our sample effect size is <em>d</em> = 0.62. Furthermore, the wide confidence interval on <em>d</em> means that our sample effect size has considerable uncertainty. All values in the confidence interval can be considered plausible values for the true population effect size. Indeed, in this unusual situation where we know the population effect size with certainty, we can see that the confidence interval on the sample effect size actually captures the true value (this will not always be the case).</p>
<p>The important take-home message for power analysis is that we want to use <strong><em>population effect size</em></strong> and <strong><em>not the sample effect size</em></strong> as our effect size input. When we identify sample effect sizes in the literature (which may be through individual studies, meta-analysis, or when appropriate, through internal pilot studies) we must be mindful that the sample effect size may not be equal to the true population effect size. If we were to use the sample effect size in the above example (<em>d</em> = 0.62) as our estimate of the population effect size in a power analysis, this would have resulted in much less power than we desired. The sample effect size has <strong><em>overestimated</em></strong> the true population effect size. Uncertainty in the population effect size is captured by the 95% CI on the sample effect size. It is wise to take this into consideration when using previously reported effect sizes for a power analysis.</p>
</div>
<div id="safeguard-effect-size" class="section level2">
<h2><span class="header-section-number">1.5</span> Safeguard Effect Size</h2>
<p>Our estimate of the population effect size is an educated guess based on the best information available to us (much like the written hypotheses we have for a study). It’s accuracy can have critical implications for the sample size required to attain a certain level of power. For this reason, researchers should routinely consider varying their effect size estimate and assessing the impact this has on their power analysis. If we are using sample effect sizes reported in the literature to estimate the population effect size, one excellent recommendation is to formally consider the uncertainty of sample effect sizes. That is, take into account the 95% CI on these reported effects.</p>
<p>Consider once again the data reported in the previous section. If you skipped ahead, we simulated a study where the true population effect size was Cohen’s <span class="math inline">\(\delta\)</span> = 0.5. However, we obtained a sample estimate of this effect size as Cohen’s <em>d</em> = 0.62 in a sample of <em>N</em> = 40 observations. Were we to use <em>d</em> = 0.62 as our power analysis input, this would result in much less power than anticipated to detect an effect size of <span class="math inline">\(\delta\)</span> = 0.5. So what should we do?</p>
<p><span class="citation">Perugini, Gallucci, and Costantini (<a href="#ref-Perugini2014" role="doc-biblioref">2014</a>)</span> suggest we take into account the uncertainty of the sample effect size. To do so, they suggest for the researcher to compute the lower absolute limit of a 60% CI on the sample effect. This value would then be used as a <strong><em>safeguard effect size</em></strong> and inputted into a power analysis. Why 60%? Well, the lower limit of a 60% CI corresponds to a one-sided 80% CI. As <span class="citation">Perugini, Gallucci, and Costantini (<a href="#ref-Perugini2014" role="doc-biblioref">2014</a>)</span> describe, this implies a 20% risk that that the true population effect size is lower than this limit, and correspondingly, 80% assurance that the population effect size is equal to or greater than this limit. We focus on the lower boundary because of the asymmetry of overestimating compared to underestimating the population effect size in a power analysis.</p>
<p>Let’s do this for our previous sample estimate of Cohen’s <em>d</em>. We can compute a 60% CI by changing the <code>conf.level</code> parameter to 0.60 in <code>MBESS::ci.smd()</code>:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="introduction-to-power-analysis.html#cb14-1"></a>(<span class="dt">d_safeguard =</span> MBESS<span class="op">::</span><span class="kw">ci.smd</span>(<span class="dt">smd =</span> d, <span class="dt">n.1 =</span> n1, <span class="dt">n.2 =</span> n2, <span class="dt">conf.level =</span> <span class="fl">0.60</span>))</span></code></pre></div>
<pre><code>## $Lower.Conf.Limit.smd
## [1] 0.3437032
## 
## $smd
## [1] 0.6205506
## 
## $Upper.Conf.Limit.smd
## [1] 0.8892221</code></pre>
<p>Using our sample Cohen’s <em>d</em> = 0.62 in a sample of <em>N</em> = 40, the lower absolute limit of a 60% CI on this effect is 0.34. We would therefore use the safeguard sample effect size as our best estimate of the population effect size in our power analysis. While we have somewhat underestimated the population effect size in this scenario, we have also ensured we have sufficient power to detect the population effect size. Sufficient power means we are more likely to draw correct inferences from our data.</p>
</div>
<div id="post-hoc-power-analysis" class="section level2">
<h2><span class="header-section-number">1.6</span> <em>Post hoc</em> power analysis</h2>
<p>All authors of this book are in agreement: <em>post hoc</em> power analysis is useless. Many statisticians have made this abundantly clear <span class="citation">(Gelman <a href="#ref-gelman2019don" role="doc-biblioref">2019</a>; Althouse <a href="#ref-Althouse2021" role="doc-biblioref">2021</a>)</span>.</p>
<p>Sometimes editors or reviewers of manuscripts will insist that an author perform a post-experiment power calculation in order to interpret non-significant findings. These <em>post hoc</em> or <em>observed</em> power calculations are requested on the basis of explaining the observed data rather than planning some future experiment. These analyses are intended to answer the question: <em>“On the basis of my observed effect size, did I have enough power to reject my null hypothesis?”</em>. To avoid needless suspense, the answer is always: no.</p>
<p>We will discuss two reasons why <em>post hoc</em> power analyses are a problematic practice.</p>
<div id="the-sample-effect-size-is-not-the-population-effect-size" class="section level3">
<h3><span class="header-section-number">1.6.1</span> The sample effect size is <em>not</em> the population effect size</h3>
<p>As discussed at length in <a href="introduction-to-power-analysis.html#samp_vs_pop">previous sections</a>, the sample effect size is <strong><em>not</em></strong> the population effect size. For this simple reason alone, any <em>post hoc</em> power calculation will be an inaccurate estimate of the true power of an experiment. To illustrate, consider once more our simulated data set. If you skipped ahead, we simulated random sample of <em>N</em> = 40 from two populations (<span class="math inline">\(n_1\)</span> = 20, <span class="math inline">\(n_2\)</span> = 20) where the true population effect size was Cohen’s <span class="math inline">\(\delta\)</span> = 0.5. However, based on random sampling alone, we obtained a sample effect size of Cohen’s <em>d</em> = 0.62.</p>
<p>If we perform a <em>t</em>-test on these data, we will find that the data are compatible with the null hypothesis of no difference. That is, <em>p</em> &gt; .05. This is exactly the kind of scenario targeted by proponents of <em>post hoc</em> power analysis. Let’s perform the test:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="introduction-to-power-analysis.html#cb16-1"></a><span class="kw">t.test</span>(<span class="dt">x =</span> group_<span class="dv">1</span>, <span class="dt">y =</span> group_<span class="dv">2</span>, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  group_1 and group_2
## t = 1.9624, df = 38, p-value = 0.05707
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.02199628  1.41348186
## sample estimates:
##     mean of x     mean of y 
##  0.6954610335 -0.0002817572</code></pre>
<p>We obtain <em>p</em> = .057. Now let’s compute a <em>post hoc</em> power calculation on the sample effect size. As will be explained in later sections, we can compute different kinds of power analyses by omitting a single parameter in a power function. Here, we omit <code>power</code> and ask <code>pwr::pwr.t.test()</code> to estimate <code>power</code> on the basis of <em>n</em> = 20 per group (total <em>N</em> = 40) using <em>d</em> = 0.62 and <span class="math inline">\(\alpha\)</span> = .05 (two-sided):</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="introduction-to-power-analysis.html#cb18-1"></a><span class="co"># Remind ourselves of the value of Cohen&#39;s d for these data:</span></span>
<span id="cb18-2"><a href="introduction-to-power-analysis.html#cb18-2"></a>(d)</span></code></pre></div>
<pre><code>## [1] 0.6205506</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="introduction-to-power-analysis.html#cb20-1"></a><span class="co"># Perform the post hoc power analysis by excluding `power`. Note: `n` refers to sample size &#39;per group&#39;:</span></span>
<span id="cb20-2"><a href="introduction-to-power-analysis.html#cb20-2"></a>pwr<span class="op">::</span><span class="kw">pwr.t.test</span>(<span class="dt">n =</span> <span class="dv">20</span>, <span class="dt">d =</span> d, <span class="dt">sig.level =</span> <span class="fl">0.05</span>)</span></code></pre></div>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 20
##               d = 0.6205506
##       sig.level = 0.05
##           power = 0.4811947
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>Our estimate of <em>post hoc</em> power is 48%. However, we know that the true population effect size is <span class="math inline">\(\delta\)</span> = 0.5. With this knowledge, we can compute the <em>true</em> power of our test as:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="introduction-to-power-analysis.html#cb22-1"></a><span class="co"># Define delta</span></span>
<span id="cb22-2"><a href="introduction-to-power-analysis.html#cb22-2"></a>delta =<span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb22-3"><a href="introduction-to-power-analysis.html#cb22-3"></a></span>
<span id="cb22-4"><a href="introduction-to-power-analysis.html#cb22-4"></a><span class="co"># Perform the post hoc power analysis by excluding `power`:</span></span>
<span id="cb22-5"><a href="introduction-to-power-analysis.html#cb22-5"></a>pwr<span class="op">::</span><span class="kw">pwr.t.test</span>(<span class="dt">n =</span> <span class="dv">20</span>, <span class="dt">d =</span> delta, <span class="dt">sig.level =</span> <span class="fl">0.05</span>)</span></code></pre></div>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 20
##               d = 0.5
##       sig.level = 0.05
##           power = 0.337939
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>The true power based on the population effect size is 34%. This is much lower than our <em>post hoc</em> power analysis has lead us to believe. As such, <em>post hoc</em> power analysis will not tell you whether you had enough power to reject the null hypothesis. That is, unless you are willing to assume your sample effect size <em>is</em> the population effect size. This is something a single study cannot tell you. And this is something that is clearly incorrect in our example.</p>
</div>
<div id="post-hoc-power-is-merely-a-transformation-of-your-obtained-p-value" class="section level3">
<h3><span class="header-section-number">1.6.2</span> <em>Post hoc</em> power is merely a transformation of your obtained <em>p</em> value</h3>
<p><em>Post hoc</em> power analyses are simply a re-expression of the obtained <em>p</em> value. As <span class="citation">Lenth (<a href="#ref-Lenth2007" role="doc-biblioref">2007</a>)</span> describes, to compute <em>post hoc</em> power all we need (beyond our chosen <span class="math inline">\(\alpha\)</span>) is the <em>p</em> value of the test and associated degrees of freedom. For this reason, <em>post hoc</em> power does not provide more information than that which is already provided by our <em>p</em> value.</p>
<p>Recall from above that our obtained <em>p</em> value in our simulated data is .057. <span class="citation">Lenth (<a href="#ref-Lenth2007" role="doc-biblioref">2007</a>)</span> provides a simple R function to compute <em>post hoc</em> power from the obtained <em>p</em> value from an independent groups <em>t</em> test as follows:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="introduction-to-power-analysis.html#cb24-1"></a><span class="co"># Define power function</span></span>
<span id="cb24-2"><a href="introduction-to-power-analysis.html#cb24-2"></a>power &lt;-<span class="st"> </span><span class="cf">function</span>(p_val, deg_f, alpha){</span>
<span id="cb24-3"><a href="introduction-to-power-analysis.html#cb24-3"></a></span>
<span id="cb24-4"><a href="introduction-to-power-analysis.html#cb24-4"></a>  delta =<span class="st"> </span><span class="kw">qt</span>(<span class="dt">p =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p_val <span class="op">/</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">df =</span> deg_f)</span>
<span id="cb24-5"><a href="introduction-to-power-analysis.html#cb24-5"></a>  crit_val =<span class="st"> </span><span class="kw">qt</span>(<span class="dt">p =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha <span class="op">/</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">df =</span> deg_f)</span>
<span id="cb24-6"><a href="introduction-to-power-analysis.html#cb24-6"></a>  power =<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pt</span>(<span class="dt">q =</span> crit_val, <span class="dt">df =</span> deg_f, <span class="dt">ncp =</span> delta) <span class="op">+</span><span class="st"> </span><span class="kw">pt</span>(<span class="op">-</span>crit_val, deg_f, delta)</span>
<span id="cb24-7"><a href="introduction-to-power-analysis.html#cb24-7"></a>  </span>
<span id="cb24-8"><a href="introduction-to-power-analysis.html#cb24-8"></a>  <span class="kw">return</span>(power)</span>
<span id="cb24-9"><a href="introduction-to-power-analysis.html#cb24-9"></a></span>
<span id="cb24-10"><a href="introduction-to-power-analysis.html#cb24-10"></a>}</span></code></pre></div>
<p>Let’s apply this function to our obtained <em>p</em> value and associated degrees of freedom:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="introduction-to-power-analysis.html#cb25-1"></a><span class="co"># Apply power function to our data</span></span>
<span id="cb25-2"><a href="introduction-to-power-analysis.html#cb25-2"></a><span class="kw">power</span>(<span class="dt">p_val =</span> <span class="fl">0.05707</span>, <span class="dt">deg_f =</span> <span class="dv">38</span>, <span class="dt">alpha =</span> <span class="fl">.05</span>)</span></code></pre></div>
<pre><code>## [1] 0.4812096</code></pre>
<p>Using only the obtained <em>p</em> value and test degrees of freedom we obtain a <em>post hoc</em> power of 48%. This is identical to our power analysis based on the observed effect size (with error due to rounding of our <em>p</em> value). We could do this with any combination of obtained <em>p</em> value and degrees of freedom, and obtain exactly the result of a <em>post hoc</em> power analysis.</p>
<p>In general, the power of a test yielding exactly <em>p</em> = .05 will be around 50% (and inches ever closer to exactly 50% as degrees of freedom approaches infinity). If <em>p</em> &gt; .05, power (in general) will be less than 50%. To demonstrate, let’s test this with our function using degrees of freedom from five to infinity against <em>p</em> values of .05, .10, and .20:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="introduction-to-power-analysis.html#cb27-1"></a>v =<span class="st"> </span><span class="kw">list</span>(<span class="kw">seq</span>(<span class="dv">20</span>,<span class="dv">200</span>,<span class="dv">20</span>), <span class="ot">Inf</span>)</span>
<span id="cb27-2"><a href="introduction-to-power-analysis.html#cb27-2"></a><span class="kw">map_df</span>(v, <span class="op">~</span><span class="st"> </span><span class="kw">data.frame</span>(., </span>
<span id="cb27-3"><a href="introduction-to-power-analysis.html#cb27-3"></a>                       <span class="kw">power</span>(<span class="dt">p_val =</span> <span class="fl">.05</span>, <span class="dt">deg_f =</span> ., <span class="dt">alpha =</span> <span class="fl">.05</span>), </span>
<span id="cb27-4"><a href="introduction-to-power-analysis.html#cb27-4"></a>                       <span class="kw">power</span>(<span class="dt">p_val =</span> <span class="fl">0.10</span>, <span class="dt">deg_f =</span> ., <span class="dt">alpha =</span> <span class="fl">.05</span>),</span>
<span id="cb27-5"><a href="introduction-to-power-analysis.html#cb27-5"></a>                       <span class="kw">power</span>(<span class="dt">p_val =</span> <span class="fl">0.20</span>, <span class="dt">deg_f =</span> ., <span class="dt">alpha =</span> <span class="fl">.05</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb27-6"><a href="introduction-to-power-analysis.html#cb27-6"></a><span class="st">  `</span><span class="dt">colnames&lt;-</span><span class="st">`</span>(<span class="kw">c</span>(<span class="st">&quot;Degrees of Freedom&quot;</span>, </span>
<span id="cb27-7"><a href="introduction-to-power-analysis.html#cb27-7"></a>                 <span class="st">&quot;Power ($p$ = .05)&quot;</span>,</span>
<span id="cb27-8"><a href="introduction-to-power-analysis.html#cb27-8"></a>                 <span class="st">&quot;Power ($p$ = .10)&quot;</span>, </span>
<span id="cb27-9"><a href="introduction-to-power-analysis.html#cb27-9"></a>                 <span class="st">&quot;Power ($p$ = .20)&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb27-10"><a href="introduction-to-power-analysis.html#cb27-10"></a><span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(<span class="dt">escape =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb27-11"><a href="introduction-to-power-analysis.html#cb27-11"></a><span class="st">  </span>kableExtra<span class="op">::</span><span class="kw">kable_styling</span>(<span class="dt">bootstrap_options =</span> <span class="st">&quot;striped&quot;</span>, </span>
<span id="cb27-12"><a href="introduction-to-power-analysis.html#cb27-12"></a>                            <span class="dt">full_width =</span> T, </span>
<span id="cb27-13"><a href="introduction-to-power-analysis.html#cb27-13"></a>                            <span class="dt">position =</span> <span class="st">&quot;left&quot;</span>)</span></code></pre></div>
<table class="table table-striped" style="">
<thead>
<tr>
<th style="text-align:right;">
Degrees of Freedom
</th>
<th style="text-align:right;">
Power (<span class="math inline">\(p\)</span> = .05)
</th>
<th style="text-align:right;">
Power (<span class="math inline">\(p\)</span> = .10)
</th>
<th style="text-align:right;">
Power (<span class="math inline">\(p\)</span> = .20)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
0.5101846
</td>
<td style="text-align:right;">
0.3754240
</td>
<td style="text-align:right;">
0.2432919
</td>
</tr>
<tr>
<td style="text-align:right;">
40
</td>
<td style="text-align:right;">
0.5050221
</td>
<td style="text-align:right;">
0.3759611
</td>
<td style="text-align:right;">
0.2463210
</td>
</tr>
<tr>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
0.5033422
</td>
<td style="text-align:right;">
0.3761399
</td>
<td style="text-align:right;">
0.2473313
</td>
</tr>
<tr>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
0.5025099
</td>
<td style="text-align:right;">
0.3762290
</td>
<td style="text-align:right;">
0.2478362
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
0.5020131
</td>
<td style="text-align:right;">
0.3762824
</td>
<td style="text-align:right;">
0.2481391
</td>
</tr>
<tr>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
0.5016829
</td>
<td style="text-align:right;">
0.3763180
</td>
<td style="text-align:right;">
0.2483409
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
0.5014475
</td>
<td style="text-align:right;">
0.3763434
</td>
<td style="text-align:right;">
0.2484851
</td>
</tr>
<tr>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
0.5012713
</td>
<td style="text-align:right;">
0.3763624
</td>
<td style="text-align:right;">
0.2485932
</td>
</tr>
<tr>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
0.5011344
</td>
<td style="text-align:right;">
0.3763772
</td>
<td style="text-align:right;">
0.2486773
</td>
</tr>
<tr>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
0.5010250
</td>
<td style="text-align:right;">
0.3763890
</td>
<td style="text-align:right;">
0.2487446
</td>
</tr>
<tr>
<td style="text-align:right;">
Inf
</td>
<td style="text-align:right;">
0.5000443
</td>
<td style="text-align:right;">
0.3764951
</td>
<td style="text-align:right;">
0.2493496
</td>
</tr>
</tbody>
</table>
<p>As we can see, whenever a test is non-significant (as it was in our example) the power will usually be less than 50%. Therefore, whenever you are motivated to perform a <em>post hoc</em> power analysis to explain a non-significant result, it is an empty question of whether <em>post hoc</em> power is high. The answer, as we alluded to earlier, is always <em>no</em>. In our simulated dataset we already knew that <em>p</em> &gt; .05, so of course this must mean we had low power. Otherwise we would not have obtained <em>p</em> &gt; .05! <em>Post hoc</em> power is a mere transformation of the <em>p</em> value and provides us with no new information than that we already knew.</p>
<p>Power calculations are useful for designing experiments and planning studies. They are not useful once the data is collected and the final analyses have been completed. Keep this in mind when performing your own power analyses, or attempting to explain non-significant results.</p>
</div>
</div>
<div id="the-minimal-detectable-effect-size" class="section level2">
<h2><span class="header-section-number">1.7</span> The Minimal Detectable Effect Size</h2>
<p>In an ideal world all studies would proceed with sample sizes that give sufficient power to detect population effects. However, we operate within a world of limited resources, and there are often times where researchers are unable to increase sample sizes to attain a specific power. If an experiment is performed in this context, rather than calculating something like <em>post hoc</em> power, it is much more informative to compute the smallest effect size that could be detected in a study of this particular sample size. This requires fixing the <span class="math inline">\(\alpha\)</span> level and sample size, and computing the critical test statistic for the proposed (or conducted) statistical analysis.</p>
<p>We will once again draw on the simulated dataset we introduced <a href="introduction-to-power-analysis.html#samp_vs_pop">above</a>. This dataset was generated by drawing a random sample of <em>N</em> = 40 from two populations (<span class="math inline">\(n_1\)</span> = 20, <span class="math inline">\(n_2\)</span> = 20) where the true population effect size was Cohen’s <span class="math inline">\(\delta\)</span> = 0.5. However, the obtained sample effect size was Cohen’s <em>d</em> = 0.62. Furthermore, using an independent groups <em>t</em>-test (<span class="math inline">\(\alpha\)</span> = .05; two-sided) we found that this effect was non-significant (<em>p</em> = .057). Let’s compute what minimum <em>t</em> value was necessary to attain statistical significance. This is the critical <em>t</em> value, which can be computed with the <code>qt()</code> function in R:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="introduction-to-power-analysis.html#cb28-1"></a>n1 =<span class="st"> </span><span class="kw">length</span>(group_<span class="dv">1</span>)</span>
<span id="cb28-2"><a href="introduction-to-power-analysis.html#cb28-2"></a>n2 =<span class="st"> </span><span class="kw">length</span>(group_<span class="dv">2</span>)</span>
<span id="cb28-3"><a href="introduction-to-power-analysis.html#cb28-3"></a>alpha =<span class="st"> </span><span class="fl">.05</span></span>
<span id="cb28-4"><a href="introduction-to-power-analysis.html#cb28-4"></a>deg_f =<span class="st"> </span>n1 <span class="op">+</span><span class="st"> </span>n2 <span class="op">-</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb28-5"><a href="introduction-to-power-analysis.html#cb28-5"></a>(<span class="dt">t_crit =</span> <span class="kw">qt</span>(<span class="dt">p =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(alpha<span class="op">/</span><span class="dv">2</span>), <span class="dt">df =</span> deg_f))</span></code></pre></div>
<pre><code>## [1] 2.024394</code></pre>
<p>The critical <em>t</em> value for our test is 2.024. This means that any obtained <em>t</em> statistic lower than this value will yield a statistically non-significant result (i.e., <em>p</em> &gt; .05). Our <em>t</em> statistic was 1.96, so it is unsurprising that our result was non-significant.</p>
<p>There is an algebraic solution to converting an obtained independent groups <em>t</em> statistic (two sample <em>t</em>-test) to a Cohen’s <em>d</em> value:</p>
<p><span class="math display">\[d = t* \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}\]</span></p>
<p>Here, <em>t</em> is the obtained <em>t</em> statistic from an independent groups <em>t</em> test, and <span class="math inline">\(n1\)</span> and <span class="math inline">\(n2\)</span> are the sample sizes of each group, respectively. We can confirm that <em>d</em> = 0.62 in our data on the basis of the <em>t</em> statistic and sample sizes alone:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="introduction-to-power-analysis.html#cb30-1"></a><span class="co"># Store the t test result</span></span>
<span id="cb30-2"><a href="introduction-to-power-analysis.html#cb30-2"></a>result =<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> group_<span class="dv">1</span>, <span class="dt">y =</span> group_<span class="dv">2</span>, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)</span>
<span id="cb30-3"><a href="introduction-to-power-analysis.html#cb30-3"></a></span>
<span id="cb30-4"><a href="introduction-to-power-analysis.html#cb30-4"></a><span class="co"># Extract the t value</span></span>
<span id="cb30-5"><a href="introduction-to-power-analysis.html#cb30-5"></a>(<span class="dt">t_val =</span> <span class="kw">as.numeric</span>(result<span class="op">$</span>statistic))</span></code></pre></div>
<pre><code>## [1] 1.962353</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="introduction-to-power-analysis.html#cb32-1"></a><span class="co"># Store the sample size of each group</span></span>
<span id="cb32-2"><a href="introduction-to-power-analysis.html#cb32-2"></a>n1 =<span class="st"> </span><span class="kw">length</span>(group_<span class="dv">1</span>)</span>
<span id="cb32-3"><a href="introduction-to-power-analysis.html#cb32-3"></a>n2 =<span class="st"> </span><span class="kw">length</span>(group_<span class="dv">2</span>)</span>
<span id="cb32-4"><a href="introduction-to-power-analysis.html#cb32-4"></a></span>
<span id="cb32-5"><a href="introduction-to-power-analysis.html#cb32-5"></a><span class="co"># Compute Cohen&#39;s d from the t statistic and sample sizes alone</span></span>
<span id="cb32-6"><a href="introduction-to-power-analysis.html#cb32-6"></a>t_val <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>((<span class="dv">1</span><span class="op">/</span>n1 <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>n2))</span></code></pre></div>
<pre><code>## [1] 0.6205506</code></pre>
<p><em>d</em> = 0.62. Magic. We can take advantage of this formula and, instead of inputting the obtained <em>t</em> statistic, we can input the critical <em>t</em> statistic for a study of this size. In doing so, we will obtain a critical <em>d</em> value:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="introduction-to-power-analysis.html#cb34-1"></a><span class="co"># Remind ourselves of what t_crit is</span></span>
<span id="cb34-2"><a href="introduction-to-power-analysis.html#cb34-2"></a>(t_crit)</span></code></pre></div>
<pre><code>## [1] 2.024394</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="introduction-to-power-analysis.html#cb36-1"></a><span class="co"># Compute the critical d value</span></span>
<span id="cb36-2"><a href="introduction-to-power-analysis.html#cb36-2"></a>t_crit <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>((<span class="dv">1</span><span class="op">/</span>n1 <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>n2))</span></code></pre></div>
<pre><code>## [1] 0.6401696</code></pre>
<p>In a study of this size the critical <em>d</em> value is 0.64. This means that any obtained <em>d</em> statistic lower or equal to this value will yield a non-significant result (i.e., <em>p</em> &gt; .05). As we obtained <em>d</em> = 0.62 as our sample effect size, it is unsurprising that our result is non-significant. The critical <em>d</em> value of 0.64 is the minimal detectable effect size in a study of this size.</p>
<p>What does this all mean? Well, if a researcher believes that the true population effect size is less than 0.62 (perhaps, <span class="math inline">\(\delta\)</span> = 0.5), they should be un-surprised if they find a non-significant finding in <em>N</em> = 40. The minimum effect size they could have hoped to have detected was <em>d</em> = 0.66. The non-significant result is explained by the fact that a study of this sample size cannot detect effect sizes below the critical <em>d</em> value. In later chapters we will discuss how to use <code>Superpower</code> to address these issues using tools such as the <code>plot_power</code> function and the <code>morey_plot</code> functions.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-albers2018power">
<p>Albers, Casper, and Daniël Lakens. 2018. “When Power Analyses Based on Pilot Data Are Biased: Inaccurate Effect Size Estimators and Follow-up Bias.” <em>Journal of Experimental Social Psychology</em> 74: 187–95. <a href="https://doi.org/10.1016/j.jesp.2017.09.004">https://doi.org/10.1016/j.jesp.2017.09.004</a>.</p>
</div>
<div id="ref-Althouse2021">
<p>Althouse, Andrew D. 2021. “Post Hoc Power: Not Empowering, Just Misleading.” <em>Journal of Surgical Research</em> 259 (March): A3–A6. <a href="https://doi.org/10.1016/j.jss.2019.10.049">https://doi.org/10.1016/j.jss.2019.10.049</a>.</p>
</div>
<div id="ref-Caldwell2020">
<p>Caldwell, Aaron, and Andrew D. Vigotsky. 2020. “A Case Against Default Effect Sizes in Sport and Exercise Science.” <em>PeerJ</em> 8 (November): e10314. <a href="https://doi.org/10.7717/peerj.10314">https://doi.org/10.7717/peerj.10314</a>.</p>
</div>
<div id="ref-gelman2019don">
<p>Gelman, Andrew. 2019. “Don’t Calculate Post-Hoc Power Using Observed Estimate of Effect Size.” <em>Annals of Surgery</em> 269 (1): e9–e10.</p>
</div>
<div id="ref-Lenth2007">
<p>Lenth, Russell V. 2007. “Statistical Power Calculations.” <em>Journal of Animal Science</em> 85 (suppl_13): E24–E29.</p>
</div>
<div id="ref-Perugini2014">
<p>Perugini, Marco, Marcello Gallucci, and Giulio Costantini. 2014. “Safeguard Power as a Protection Against Imprecise Power Estimates.” <em>Perspectives on Psychological Science</em> 9 (3): 319–32.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-experimental-design.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["SuperpowerValidation.pdf", "SuperpowerValidation.epub"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
